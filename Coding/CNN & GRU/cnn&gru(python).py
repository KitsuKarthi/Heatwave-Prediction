# -*- coding: utf-8 -*-
"""CNN&GRU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XHi2DWrDhV5jKGD2SzWbqy5A1la-vpGm
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, Dense, Dropout,Flatten
from tensorflow.keras import initializers
from tensorflow.keras.layers import GRU

data = pd.read_csv('/content/finaldataset_normalized.csv', header=0, infer_datetime_format=True)

n_steps=10

input_cols = data.columns
input_cols=input_cols.delete(0)
input_cols=input_cols.delete(8)

output_cols = ['maxtemp']

# Create the training and testing datasets
train_data = data.loc[data['datetime']<='2014-12-31']
test_data = data.loc[data['datetime']>='2015-01-01']

def to_sequences(data, n_steps, input_cols, output_cols):
    X, y = [], []
    for i in range(len(data)-n_steps):
        x = data[input_cols].values[i:i+n_steps]
        X.append(x)
        for col in output_cols:
            y.append(data[col].values[i+n_steps])
    return np.array(X), np.array(y)

train_X, train_y = to_sequences(train_data, n_steps, input_cols, output_cols)
test_X, test_y = to_sequences(test_data, n_steps, input_cols, output_cols)

initializer = initializers.GlorotUniform()

# Define the model architecture
model = Sequential()
model.add(Conv1D(filters=224, kernel_size=1, strides=1, activation='relu', kernel_initializer=initializer, input_shape=(n_steps, len(input_cols))))
model.add(Conv1D(filters=192, kernel_size=1, strides=1, activation='relu', kernel_initializer=initializer))
model.add(Dropout(0.3))

# Gated Recurrent Unit (GRU) layers
model.add(GRU(64, activation='relu', kernel_initializer=initializer, return_sequences=True))
model.add(GRU(64, activation='relu', kernel_initializer=initializer, return_sequences=True))
model.add(GRU(64, activation='relu', kernel_initializer=initializer))

model.add(Flatten())
model.add(Dropout(0.1))

model.add(Dense(len(output_cols), kernel_initializer=initializer))
model.compile(optimizer='adam', loss='mse')
model.summary()

# Train the model
epochs = 550
batch_size = 60
model.fit(train_X, train_y, epochs=epochs, verbose=1)

# Evaluate the model
pred_y = model.predict(test_X)

# Calculate RMSE
rmse = mean_squared_error(test_y, pred_y, squared=False)

# Calculate CC
cc = np.corrcoef(test_y, pred_y.reshape(-1))[0, 1]

# Calculate NSE
nse = 1 - (np.sum((test_y - pred_y.flatten())**2) / np.sum((test_y - np.mean(test_y))**2))

print('RMSE:', rmse)
print('CC:', cc)
print('NSE:', nse)

result = pd.DataFrame()
result['test_y']=test_y
result['pred_y']=pred_y

x = np.array(["Day 1","Day 2","Day 3","Day 4","Day 5"])
y = np.array([0.249293,0.304127,0.247315,0.277841,0.303844])
plt.bar(x,y)
plt.title("Heatwave Prediction")
plt.xlabel("Days")
plt.ylabel("Temperature Â°C")

n_future = 5
DayWise = []
for i in range(1,n_future+1):
  Day_rmse = mean_squared_error(test_y[:i], pred_y[:i], squared=False)
  DayWise.append(Day_rmse)
  print("Day",i," : ",Day_rmse)

Five_Days_rmse = mean_squared_error(test_y[:5], pred_y[:5], squared=False)
Five_Days_rmse

x = np.array(["Day 1","Day 2","Day 3","Day 4","Day 5"])
y = np.array(DayWise)
plt.bar(x,y)
plt.title("Heatwave Prediction")
plt.xlabel("Days")
plt.ylabel("Accuray(%)")